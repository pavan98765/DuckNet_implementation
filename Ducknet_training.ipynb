{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "857a5f70",
      "metadata": {
        "id": "857a5f70"
      },
      "outputs": [],
      "source": [
        "# Importing the necessary libraries\n",
        "import tensorflow as tf\n",
        "import albumentations as albu\n",
        "import numpy as np\n",
        "import gc\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.callbacks import CSVLogger\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import jaccard_score, precision_score, recall_score, accuracy_score, f1_score\n",
        "# from ModelArchitecture.DiceLoss import dice_metric_loss\n",
        "# from ModelArchitecture import DUCK_Net\n",
        "# from ImageLoader import ImageLoader2D"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the number of GPUs available\n",
        "\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6hyEqVvVZMv",
        "outputId": "9b2d918a-2127-49ed-bee6-8bc79bcbe2df"
      },
      "id": "f6hyEqVvVZMv",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "od9Cx7__WDzb",
        "outputId": "1bdf7df6-a8b8-4ecf-90ec-b88f16c1378e"
      },
      "id": "od9Cx7__WDzb",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Kvasir-seg dataset\n",
        "images_folder_path = \"/content/drive/MyDrive/CV_PROJECT/Kvasir-SEG_small/train/images\"\n",
        "masks_folder_path = \"/content/drive/MyDrive/CV_PROJECT/Kvasir-SEG_small/train/masks\"\n",
        "dataset_type = 'kvasir'\n",
        "model_path = \"/content/drive/MyDrive/CV_PROJECT/Pre trained Models/DuckNet34 Kvasir Tf Model\"\n",
        "\n",
        "#CVC-ClinicDB\n",
        "# images_folder_path = \"/content/drive/MyDrive/CV_PROJECT/CVC-ClinicDB/test/images\"\n",
        "# masks_folder_path = \"/content/drive/MyDrive/CV_PROJECT/CVC-ClinicDB/test/masks\"\n",
        "# dataset_type = 'cvc-clinicdb'\n",
        "# model_path = \"/content/drive/MyDrive/CV_PROJECT/Pre trained Models/DuckNet34 Cvc-ClinicDb Tf Model\"\n",
        "\n",
        "#CVC-ColonDB\n",
        "# images_folder_path = \"/content/drive/MyDrive/CV_PROJECT/CVC-ColonDB/test/images\"\n",
        "# masks_folder_path = \"/content/drive/MyDrive/CV_PROJECT/CVC-ColonDB/test/masks\"\n",
        "# dataset_type = 'cvc-colondb'\n",
        "# model_path = \"/content/drive/MyDrive/CV_PROJECT/Pre trained Models/DuckNet34 Cvc-ColonDb Tf Model\"\n",
        "\n",
        "# ETIS-LaribPolypDB\n",
        "# images_folder_path = \"/content/drive/MyDrive/CV_PROJECT/ETIS-LaribPolypDB/test/images\"\n",
        "# masks_folder_path = \"/content/drive/MyDrive/CV_PROJECT/ETIS-LaribPolypDB/test/masks\"\n",
        "# dataset_type = 'etis-laribpolypdb'\n",
        "# model_path = \"/content/drive/MyDrive/CV_PROJECT/Pre trained Models/DuckNet34 Etis-laribpolypdb Tf Model\"\n"
      ],
      "metadata": {
        "id": "KeONVrNUWBg9"
      },
      "id": "KeONVrNUWBg9",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dice loss\n",
        "\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def dice_metric_loss(ground_truth, predictions, smooth=1e-6):\n",
        "    ground_truth = K.cast(ground_truth, tf.float32)\n",
        "    predictions = K.cast(predictions, tf.float32)\n",
        "    ground_truth = K.flatten(ground_truth)\n",
        "    predictions = K.flatten(predictions)\n",
        "    intersection = K.sum(predictions * ground_truth)\n",
        "    union = K.sum(predictions) + K.sum(ground_truth)\n",
        "\n",
        "    dice = (2. * intersection + smooth) / (union + smooth)\n",
        "\n",
        "    return 1 - dice\n"
      ],
      "metadata": {
        "id": "cIypcORcVKkp"
      },
      "id": "cIypcORcVKkp",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ConvBlock2D\n",
        "\n",
        "from keras.layers import BatchNormalization, add\n",
        "from keras.layers import Conv2D\n",
        "\n",
        "kernel_initializer = \"he_uniform\"\n",
        "\n",
        "\n",
        "def conv_block_2D(\n",
        "    x, filters, block_type, repeat=1, dilation_rate=1, size=3, padding=\"same\"\n",
        "):\n",
        "    result = x\n",
        "\n",
        "    for i in range(0, repeat):\n",
        "\n",
        "        if block_type == \"separated\":\n",
        "            result = separated_conv2D_block(result, filters, size=size, padding=padding)\n",
        "        elif block_type == \"duckv2\":\n",
        "            result = duckv2_conv2D_block(result, filters, size=size)\n",
        "        elif block_type == \"midscope\":\n",
        "            result = midscope_conv2D_block(result, filters)\n",
        "        elif block_type == \"widescope\":\n",
        "            result = widescope_conv2D_block(result, filters)\n",
        "        elif block_type == \"resnet\":\n",
        "            result = resnet_conv2D_block(result, filters, dilation_rate)\n",
        "        elif block_type == \"conv\":\n",
        "            result = Conv2D(\n",
        "                filters,\n",
        "                (size, size),\n",
        "                activation=\"relu\",\n",
        "                kernel_initializer=kernel_initializer,\n",
        "                padding=padding,\n",
        "            )(result)\n",
        "        elif block_type == \"double_convolution\":\n",
        "            result = double_convolution_with_batch_normalization(\n",
        "                result, filters, dilation_rate\n",
        "            )\n",
        "\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def duckv2_conv2D_block(x, filters, size):\n",
        "    x = BatchNormalization(axis=-1)(x)\n",
        "    x1 = widescope_conv2D_block(x, filters)\n",
        "\n",
        "    x2 = midscope_conv2D_block(x, filters)\n",
        "\n",
        "    x3 = conv_block_2D(x, filters, \"resnet\", repeat=1)\n",
        "\n",
        "    x4 = conv_block_2D(x, filters, \"resnet\", repeat=2)\n",
        "\n",
        "    x5 = conv_block_2D(x, filters, \"resnet\", repeat=3)\n",
        "\n",
        "    x6 = separated_conv2D_block(x, filters, size=6, padding=\"same\")\n",
        "\n",
        "    x = add([x1, x2, x3, x4, x5, x6])\n",
        "\n",
        "    x = BatchNormalization(axis=-1)(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def separated_conv2D_block(x, filters, size=3, padding=\"same\"):\n",
        "    x = Conv2D(\n",
        "        filters,\n",
        "        (1, size),\n",
        "        activation=\"relu\",\n",
        "        kernel_initializer=kernel_initializer,\n",
        "        padding=padding,\n",
        "    )(x)\n",
        "\n",
        "    x = BatchNormalization(axis=-1)(x)\n",
        "\n",
        "    x = Conv2D(\n",
        "        filters,\n",
        "        (size, 1),\n",
        "        activation=\"relu\",\n",
        "        kernel_initializer=kernel_initializer,\n",
        "        padding=padding,\n",
        "    )(x)\n",
        "\n",
        "    x = BatchNormalization(axis=-1)(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def midscope_conv2D_block(x, filters):\n",
        "    x = Conv2D(\n",
        "        filters,\n",
        "        (3, 3),\n",
        "        activation=\"relu\",\n",
        "        kernel_initializer=kernel_initializer,\n",
        "        padding=\"same\",\n",
        "        dilation_rate=1,\n",
        "    )(x)\n",
        "\n",
        "    x = BatchNormalization(axis=-1)(x)\n",
        "\n",
        "    x = Conv2D(\n",
        "        filters,\n",
        "        (3, 3),\n",
        "        activation=\"relu\",\n",
        "        kernel_initializer=kernel_initializer,\n",
        "        padding=\"same\",\n",
        "        dilation_rate=2,\n",
        "    )(x)\n",
        "\n",
        "    x = BatchNormalization(axis=-1)(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def widescope_conv2D_block(x, filters):\n",
        "    x = Conv2D(\n",
        "        filters,\n",
        "        (3, 3),\n",
        "        activation=\"relu\",\n",
        "        kernel_initializer=kernel_initializer,\n",
        "        padding=\"same\",\n",
        "        dilation_rate=1,\n",
        "    )(x)\n",
        "\n",
        "    x = BatchNormalization(axis=-1)(x)\n",
        "\n",
        "    x = Conv2D(\n",
        "        filters,\n",
        "        (3, 3),\n",
        "        activation=\"relu\",\n",
        "        kernel_initializer=kernel_initializer,\n",
        "        padding=\"same\",\n",
        "        dilation_rate=2,\n",
        "    )(x)\n",
        "\n",
        "    x = BatchNormalization(axis=-1)(x)\n",
        "\n",
        "    x = Conv2D(\n",
        "        filters,\n",
        "        (3, 3),\n",
        "        activation=\"relu\",\n",
        "        kernel_initializer=kernel_initializer,\n",
        "        padding=\"same\",\n",
        "        dilation_rate=3,\n",
        "    )(x)\n",
        "\n",
        "    x = BatchNormalization(axis=-1)(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def resnet_conv2D_block(x, filters, dilation_rate=1):\n",
        "    x1 = Conv2D(\n",
        "        filters,\n",
        "        (1, 1),\n",
        "        activation=\"relu\",\n",
        "        kernel_initializer=kernel_initializer,\n",
        "        padding=\"same\",\n",
        "        dilation_rate=dilation_rate,\n",
        "    )(x)\n",
        "\n",
        "    x = Conv2D(\n",
        "        filters,\n",
        "        (3, 3),\n",
        "        activation=\"relu\",\n",
        "        kernel_initializer=kernel_initializer,\n",
        "        padding=\"same\",\n",
        "        dilation_rate=dilation_rate,\n",
        "    )(x)\n",
        "    x = BatchNormalization(axis=-1)(x)\n",
        "    x = Conv2D(\n",
        "        filters,\n",
        "        (3, 3),\n",
        "        activation=\"relu\",\n",
        "        kernel_initializer=kernel_initializer,\n",
        "        padding=\"same\",\n",
        "        dilation_rate=dilation_rate,\n",
        "    )(x)\n",
        "    x = BatchNormalization(axis=-1)(x)\n",
        "    x_final = add([x, x1])\n",
        "\n",
        "    x_final = BatchNormalization(axis=-1)(x_final)\n",
        "\n",
        "    return x_final\n",
        "\n",
        "\n",
        "def double_convolution_with_batch_normalization(x, filters, dilation_rate=1):\n",
        "    x = Conv2D(\n",
        "        filters,\n",
        "        (3, 3),\n",
        "        activation=\"relu\",\n",
        "        kernel_initializer=kernel_initializer,\n",
        "        padding=\"same\",\n",
        "        dilation_rate=dilation_rate,\n",
        "    )(x)\n",
        "    x = BatchNormalization(axis=-1)(x)\n",
        "    x = Conv2D(\n",
        "        filters,\n",
        "        (3, 3),\n",
        "        activation=\"relu\",\n",
        "        kernel_initializer=kernel_initializer,\n",
        "        padding=\"same\",\n",
        "        dilation_rate=dilation_rate,\n",
        "    )(x)\n",
        "    x = BatchNormalization(axis=-1)(x)\n",
        "\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "3aGuhoIgVgE9"
      },
      "id": "3aGuhoIgVgE9",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DuckNet\n",
        "import tensorflow as tf\n",
        "from keras.layers import Conv2D, UpSampling2D\n",
        "from keras.layers import add\n",
        "from keras.models import Model\n",
        "\n",
        "# from CustomLayers.ConvBlock2D import conv_block_2D\n",
        "\n",
        "kernel_initializer = 'he_uniform'\n",
        "interpolation = \"nearest\"\n",
        "\n",
        "\n",
        "def create_model(img_height, img_width, input_chanels, out_classes, starting_filters):\n",
        "    input_layer = tf.keras.layers.Input((img_height, img_width, input_chanels))\n",
        "\n",
        "    print('Starting DUCK-Net')\n",
        "\n",
        "    p1 = Conv2D(starting_filters * 2, 2, strides=2, padding='same')(input_layer)\n",
        "    p2 = Conv2D(starting_filters * 4, 2, strides=2, padding='same')(p1)\n",
        "    p3 = Conv2D(starting_filters * 8, 2, strides=2, padding='same')(p2)\n",
        "    p4 = Conv2D(starting_filters * 16, 2, strides=2, padding='same')(p3)\n",
        "    p5 = Conv2D(starting_filters * 32, 2, strides=2, padding='same')(p4)\n",
        "\n",
        "    t0 = conv_block_2D(input_layer, starting_filters, 'duckv2', repeat=1)\n",
        "\n",
        "    l1i = Conv2D(starting_filters * 2, 2, strides=2, padding='same')(t0)\n",
        "    s1 = add([l1i, p1])\n",
        "    t1 = conv_block_2D(s1, starting_filters * 2, 'duckv2', repeat=1)\n",
        "\n",
        "    l2i = Conv2D(starting_filters * 4, 2, strides=2, padding='same')(t1)\n",
        "    s2 = add([l2i, p2])\n",
        "    t2 = conv_block_2D(s2, starting_filters * 4, 'duckv2', repeat=1)\n",
        "\n",
        "    l3i = Conv2D(starting_filters * 8, 2, strides=2, padding='same')(t2)\n",
        "    s3 = add([l3i, p3])\n",
        "    t3 = conv_block_2D(s3, starting_filters * 8, 'duckv2', repeat=1)\n",
        "\n",
        "    l4i = Conv2D(starting_filters * 16, 2, strides=2, padding='same')(t3)\n",
        "    s4 = add([l4i, p4])\n",
        "    t4 = conv_block_2D(s4, starting_filters * 16, 'duckv2', repeat=1)\n",
        "\n",
        "    l5i = Conv2D(starting_filters * 32, 2, strides=2, padding='same')(t4)\n",
        "    s5 = add([l5i, p5])\n",
        "    t51 = conv_block_2D(s5, starting_filters * 32, 'resnet', repeat=2)\n",
        "    t53 = conv_block_2D(t51, starting_filters * 16, 'resnet', repeat=2)\n",
        "\n",
        "    l5o = UpSampling2D((2, 2), interpolation=interpolation)(t53)\n",
        "    c4 = add([l5o, t4])\n",
        "    q4 = conv_block_2D(c4, starting_filters * 8, 'duckv2', repeat=1)\n",
        "\n",
        "    l4o = UpSampling2D((2, 2), interpolation=interpolation)(q4)\n",
        "    c3 = add([l4o, t3])\n",
        "    q3 = conv_block_2D(c3, starting_filters * 4, 'duckv2', repeat=1)\n",
        "\n",
        "    l3o = UpSampling2D((2, 2), interpolation=interpolation)(q3)\n",
        "    c2 = add([l3o, t2])\n",
        "    q6 = conv_block_2D(c2, starting_filters * 2, 'duckv2', repeat=1)\n",
        "\n",
        "    l2o = UpSampling2D((2, 2), interpolation=interpolation)(q6)\n",
        "    c1 = add([l2o, t1])\n",
        "    q1 = conv_block_2D(c1, starting_filters, 'duckv2', repeat=1)\n",
        "\n",
        "    l1o = UpSampling2D((2, 2), interpolation=interpolation)(q1)\n",
        "    c0 = add([l1o, t0])\n",
        "    z1 = conv_block_2D(c0, starting_filters, 'duckv2', repeat=1)\n",
        "\n",
        "    output = Conv2D(out_classes, (1, 1), activation='sigmoid')(z1)\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "Pqcq8rvmVOlW"
      },
      "id": "Pqcq8rvmVOlW",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from skimage.io import imread\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "\n",
        "img_size = 352\n",
        "filters = 34 # Number of filters, the paper presents the results with 17 and 34\n",
        "\n",
        "model_type = \"DuckNet\"\n",
        "\n",
        "def load_data(img_height, img_width, images_to_be_loaded, dataset):\n",
        "    if dataset == \"kvasir\" or dataset == \"etis-laribpolypdb\" or dataset == \"cvc-clinicdb\" or dataset == \"cvc-colondb\":\n",
        "        extension = \"*.jpg\"\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported dataset type.\")\n",
        "\n",
        "    images_path = Path(images_folder_path)\n",
        "    masks_path = Path(masks_folder_path)\n",
        "\n",
        "    train_image_paths = list(images_path.glob(extension))\n",
        "\n",
        "    if images_to_be_loaded == -1 or images_to_be_loaded > len(train_image_paths):\n",
        "        images_to_be_loaded = len(train_image_paths)\n",
        "\n",
        "    X_train = np.zeros((images_to_be_loaded, img_height, img_width, 3), dtype=np.float32)\n",
        "    Y_train = np.zeros((images_to_be_loaded, img_height, img_width), dtype=np.uint8)\n",
        "\n",
        "    print(f\"Resizing validation images and masks: {images_to_be_loaded}\")\n",
        "    for n, image_path in tqdm(enumerate(train_image_paths), total=images_to_be_loaded):\n",
        "        if n >= images_to_be_loaded:\n",
        "            break\n",
        "\n",
        "        mask_path = masks_path / image_path.name\n",
        "\n",
        "        image = Image.open(image_path).resize((img_width, img_height))\n",
        "        image = np.array(image) / 255.0\n",
        "\n",
        "        mask = Image.open(mask_path).resize((img_width, img_height))\n",
        "        mask = np.array(mask)\n",
        "        mask = np.where(mask >= 127, 1, 0).astype(np.uint8)\n",
        "\n",
        "        X_train[n] = image\n",
        "        Y_train[n] = mask\n",
        "\n",
        "    Y_train = np.expand_dims(Y_train, axis=-1)\n",
        "\n",
        "    return X_train, Y_train\n",
        "\n",
        "# Example usage\n",
        "img_height, img_width = 352, 352\n",
        "images_to_be_loaded = -1 # Load all images\n",
        "# dataset_type = 'kvasir'  # Options: 'kvasir', 'cvc-clinicdb', 'cvc-colondb', 'etis-laribpolypdb'\n",
        "\n",
        "X, Y = load_data(img_height, img_width, images_to_be_loaded, dataset_type)\n",
        "print(f\"Loaded {len(X)} images and masks.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmQ7GDD1eB-l",
        "outputId": "57baec99-c9c2-4c2a-f207-25220888b587"
      },
      "id": "WmQ7GDD1eB-l",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resizing validation images and masks: 200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [01:09<00:00,  2.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 200 images and masks.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import os\n",
        "\n",
        "# Split data into training and validation sets\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the model\n",
        "img_height, img_width = 352, 352\n",
        "input_channels = 3  # Assuming RGB images\n",
        "out_classes = 1    # Binary classification for masks\n",
        "starting_filters = 34\n",
        "model = create_model(img_height, img_width, input_channels, out_classes, starting_filters)\n",
        "\n",
        "# Define the path where the model will be saved and specify the filename format\n",
        "model_directory = \"/content/drive/MyDrive/CV_PROJECT/Training_models\"\n",
        "model_filename = \"best.h5\"\n",
        "model_path = os.path.join(model_directory, model_filename)\n",
        "\n",
        "# Ensure the directory exists\n",
        "os.makedirs(model_directory, exist_ok=True)\n",
        "\n",
        "# Define the model checkpoint\n",
        "checkpoint = ModelCheckpoint(\n",
        "    model_path,\n",
        "    monitor='val_loss',\n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    mode='min'\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "model.compile(optimizer=optimizer, loss=dice_metric_loss, metrics=[dice_metric_loss])\n",
        "\n",
        "# Train the model\n",
        "epochs = 100\n",
        "batch_size = 1\n",
        "history = model.fit(\n",
        "    X_train, Y_train,\n",
        "    validation_data=(X_val, Y_val),\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    callbacks=[checkpoint],\n",
        "    verbose=1  # Set verbose to 1 for default Keras progress bar\n",
        ")\n",
        "\n",
        "print(\"Training complete. Best model saved at:\", model_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "a46R1E8yfuBT",
        "outputId": "31eb4ff4-2a91-44f7-bcb0-145fb595c582"
      },
      "id": "a46R1E8yfuBT",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting DUCK-Net\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-11279be0bbe4>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mout_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m    \u001b[0;31m# Binary classification for masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mstarting_filters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m34\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarting_filters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Define the path where the model will be saved and specify the filename format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-f8a82f83ae14>\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(img_height, img_width, input_chanels, out_classes, starting_filters)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0ml2i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstarting_filters\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0ms2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml2i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_block_2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarting_filters\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'duckv2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepeat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0ml3i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstarting_filters\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-7af1cfe12e88>\u001b[0m in \u001b[0;36mconv_block_2D\u001b[0;34m(x, filters, block_type, repeat, dilation_rate, size, padding)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseparated_conv2D_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mblock_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"duckv2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mduckv2_conv2D_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mblock_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"midscope\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmidscope_conv2D_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-7af1cfe12e88>\u001b[0m in \u001b[0;36mduckv2_conv2D_block\u001b[0;34m(x, filters, size)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mx4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_block_2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"resnet\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepeat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mx5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_block_2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"resnet\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepeat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mx6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseparated_conv2D_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"same\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-7af1cfe12e88>\u001b[0m in \u001b[0;36mconv_block_2D\u001b[0;34m(x, filters, block_type, repeat, dilation_rate, size, padding)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwidescope_conv2D_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mblock_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"resnet\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet_conv2D_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mblock_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"conv\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             result = Conv2D(\n",
            "\u001b[0;32m<ipython-input-6-7af1cfe12e88>\u001b[0m in \u001b[0;36mresnet_conv2D_block\u001b[0;34m(x, filters, dilation_rate)\u001b[0m\n\u001b[1;32m    161\u001b[0m     )(x)\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     x = Conv2D(\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/dtensor/utils.py\u001b[0m in \u001b[0;36m_wrap_function\u001b[0;34m(layer_instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m                     \u001b[0mlayout_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvariable_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_layout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0minit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_instance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;31m# Inject the layout parameter after the invocation of __init__()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/conv2d.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filters, kernel_size, strides, padding, data_format, dilation_rate, groups, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0mdilation_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilation_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m             \u001b[0muse_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_initializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0merror_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_traceback_filtering_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNameError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36mis_traceback_filtering_enabled\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m     was called).\n\u001b[1;32m     46\u001b[0m   \"\"\"\n\u001b[0;32m---> 47\u001b[0;31m   \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ENABLE_TRACEBACK_FILTERING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'value'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9edbe667",
      "metadata": {
        "id": "9edbe667",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36c30bb1-99b8-4f27-eb6b-c67ab75332d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/2 [==============>...............] - ETA: 6:21 - loss: 0.4512 - dice_metric_loss: 0.4512"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from keras.metrics import MeanIoU\n",
        "import numpy as np\n",
        "\n",
        "# Load the best model\n",
        "best_model_path = \"/content/drive/MyDrive/CV_PROJECT/Training_models/best.h5\"  # Update this path to your best model path\n",
        "model = tf.keras.models.load_model(best_model_path, custom_objects={'dice_metric_loss': dice_metric_loss})\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "scores = model.evaluate(X_val, Y_val, verbose=1)\n",
        "print(f\"Loss on validation set: {scores[0]}, Dice Metric on validation set: {scores[1]}\")\n",
        "\n",
        "# Optionally: Predict on the validation set\n",
        "predictions = model.predict(X_val)\n",
        "\n",
        "# Calculate Mean IoU for a more detailed evaluation\n",
        "num_classes = 2  # Since it's a binary classification, we have two classes (foreground and background)\n",
        "IoU_calculator = MeanIoU(num_classes=num_classes)\n",
        "IoU_calculator.update_state(np.round(predictions).astype(int), Y_val.astype(int))\n",
        "mean_IoU = IoU_calculator.result().numpy()\n",
        "print(\"Mean IoU on validation set:\", mean_IoU)\n",
        "\n",
        "# Visualize the results for a specific example\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Select a random example\n",
        "random_index = np.random.randint(0, len(X_val))\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.title('Input Image')\n",
        "plt.imshow(X_val[random_index])\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.title('True Mask')\n",
        "plt.imshow(Y_val[random_index].squeeze(), cmap='gray')\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.title('Predicted Mask')\n",
        "plt.imshow(predictions[random_index].squeeze(), cmap='gray')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eIyvvtLxrKbT"
      },
      "id": "eIyvvtLxrKbT",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}